{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from itables import show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados do INEP, IBGE e VIS Data 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_O conceito técnico de abandono é diferente de evasão. Abandono quer dizer que o aluno deixa a escola em um ano mas retorna no ano seguinte. **Evasão significa que o aluno sai da escola e não volta mais para o sistema.**_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para possibilitar a análise desejada serão agrupados dados dos [Indicadores Educacionais do INEP](https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/indicadores-educacionais), da [API de dados agregados do IBGE](https://servicodados.ibge.gov.br/api/docs/agregados?versao=3#api-Variaveis-agregadosAgregadoPeriodosPeriodosVariaveisVariavelGet) e dados do Programa Bolsa Família fornecidos pela [VIS Data 3](https://aplicacoes.cidadania.gov.br/vis/data3/v.php?q[]=r6JtZJCug7BtxKW25rV%2FfmdhhJFkl21kmK19ZnB1ZW6maX7KmZO20qfOnJm%2B6IianbSon7SfrrqqkpKcmcuppsK2iKextVi1mpyuwZxNzsmY2F1zyuDAk522pHa2YH9%2BaV6EkmOXbWSEm8GcobZVetufrL%2BrkbbHlNddmMnuslSqvaGmmZ67sliqkseU1rCYmOGuoK%2BtcHXfmrnBnGiS1KjXYK5%2B3q6noWisot6nbY6kksrAlNiscZqif2Rue2JqrGZ9f15Ny8mY2F1zv%2BGspbCslKDapm2zo6C8gaHfqZ994LuYXcVwoNqlwLNyk7jNps94bsPcuaehg3Ct7qZwyViQuNSYirSbwultdKmtqJnap7yKdFSJkWWbamSNqH1lY2ipot6nbY6Zk7bXn4qin9DgbaKxtKFa3qexb7RovcKf3aJuw9y5p6GDcKDapcCzcmjK1qCNuFTA3MCZXL%2Bdn%2BdZjbucoLbCodl7cIStfWZvdWVtpml%2BdVehv8ahin2Vw9rDoFytoa3eWbvDo5l3xqHOXrCY4a6gr61woNqlwLNyaL3Cn92ibpjuwqFfw1ad2qyybq6VvM9TqqqY0NquoquEcmGraX9%2FZF6HjmObZFPR47KiXHCYm%2ByebcWfksWBc8yjks7vsZOiqaJ4qVnBtpybd9Oi36uXhbuvmpu%2BoXSzp8K7nJ%2FAxGKqn5m87MGYm66Wp6Vrdm6cmcrGU9iyn8mbsqKgcVWf5ayybqWiw81Tz6uXfviImp20qJ%2B0n666qpKSnJnLqabCtoinsbVYtZqcrsGcTc7JmNhdc8rgwJOdtqR4tmB%2FfmlghJFml21khJvBnKG2VWLcmsCzV6S%2FxqGKfamPsYFnenhVruGeu26pnMzPl5J9lcPaw6B2gqOv5p6%2Ft5pcl9dloHFmia12VKG0qJ%2BZp8K6o028z5eTXZjJ7rJUqr2hppmeu7JYqpLHlNawmJjhrqCvrXB135q5wZxoktSo17l5vugQ4aixlq2Ze7K8nJPAxJwt3qXG3MBXgqmi%2FSaltq%2BqTaejeYpllNE%2B9lSLvalpq2l%2Ff2BQncKgLeqfxtzAVIyKe1qhmm2%2BmJ%2FLyqWKoZh9yK6ma3plbKxicKSYmcbTU9yio77uwJWgt1X9GaxttJiaGg6f056mfcuPelxwlq484m2drKGGk2OcblyA0a6gq7pVrN6prsGqjrvQUy3dpn3hrqH%2F9aGj2qxtnnlzd4mUiq2Uz%2B%2B2plysmlrGmr99aV2JlFyNk5TJ6r9UoLdVfN6nsrT62rrKooqq9gbftqNccJauPOJtnayhhpNjnG5cgNGuoKu6VZ7oWY%2BzpZK9JODNpqJ96BDdoLGkWqGabb6Yn8vKpYqhmH3IrqZremVsrGLJvnKp091lmm1miqt%2BYWx5iWqpc31%2BcV2Hu24%3D&ma=ano&dt1=2013-01-01&dt2=2021-01-01&ag=m&ultdisp=1&ultdisp=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "INTERIM_DATA_DIR = \"../data/interim\"\n",
    "PROCESSED_DATA_DIR = \"../data/processed\"\n",
    "PRIMARY_KEY = \"CO_MUNICIPIO\"\n",
    "\n",
    "COMMOM_COLUMNS = [\n",
    "    \"NU_ANO_CENSO\",\n",
    "    \"NO_REGIAO\",\n",
    "    \"SG_UF\",\n",
    "    \"CO_MUNICIPIO\",\n",
    "    \"NO_MUNICIPIO\",\n",
    "    \"NO_CATEGORIA\",\n",
    "    \"NO_DEPENDENCIA\",\n",
    "]\n",
    "DROP_COLUMNS_SET = {\n",
    "    \"NU_ANO_CENSO\",\n",
    "    \"NO_REGIAO\",\n",
    "    \"SG_UF\",\n",
    "    \"NO_MUNICIPIO\",\n",
    "    \"MED_NS_CAT_0\",\n",
    "    \"CO_UF\",\n",
    "    # \"ano\",\n",
    "}\n",
    "MERGE_COLUMNS = [\"CO_MUNICIPIO\", \"NO_CATEGORIA\", \"NO_DEPENDENCIA\"]\n",
    "state_code_map = {\n",
    "    \"AC\": 12,\n",
    "    \"AL\": 27,\n",
    "    \"AM\": 13,\n",
    "    \"AP\": 16,\n",
    "    \"BA\": 29,\n",
    "    \"CE\": 23,\n",
    "    \"DF\": 53,\n",
    "    \"ES\": 32,\n",
    "    \"GO\": 52,\n",
    "    \"MA\": 21,\n",
    "    \"MG\": 31,\n",
    "    \"MS\": 50,\n",
    "    \"MT\": 51,\n",
    "    \"PA\": 15,\n",
    "    \"PB\": 25,\n",
    "    \"PE\": 26,\n",
    "    \"PI\": 22,\n",
    "    \"PR\": 41,\n",
    "    \"RJ\": 33,\n",
    "    \"RN\": 24,\n",
    "    \"RO\": 11,\n",
    "    \"RR\": 14,\n",
    "    \"RS\": 43,\n",
    "    \"SC\": 42,\n",
    "    \"SE\": 28,\n",
    "    \"SP\": 35,\n",
    "    \"TO\": 17,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auxiliar functions\n",
    "OBJECT_COLUMNS = [*COMMOM_COLUMNS, \"NO_UF\"]\n",
    "\n",
    "\n",
    "def _cast_columns_to_float(df):\n",
    "    columns_to_convert = df.select_dtypes(include=\"object\").columns\n",
    "    columns_to_convert = [\n",
    "        col for col in columns_to_convert if col not in OBJECT_COLUMNS\n",
    "    ]\n",
    "    try:\n",
    "        df[columns_to_convert] = df[columns_to_convert].astype(float)\n",
    "    except ValueError as e:\n",
    "        print(f\"\\n\\nError converting columns to float: {e}\")\n",
    "        print(f\"Columns: {columns_to_convert}\\n\\n\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def _add_prefix_header(df, prefix):\n",
    "    columns_name_map = {}\n",
    "    columns = df.columns\n",
    "    for col in columns:\n",
    "        if col in COMMOM_COLUMNS:\n",
    "            columns_name_map[col] = col\n",
    "        else:\n",
    "            columns_name_map[col] = f\"{prefix}_{col}\"\n",
    "    return df.rename(columns=columns_name_map)\n",
    "\n",
    "\n",
    "def _get_df_info(df, df_name):\n",
    "    print(f\"------------------------ {df_name} ------------------------\")\n",
    "    df.info()\n",
    "    print(\n",
    "        f\"\\nREGISTROS NÃO REPETIDOS: {df.drop_duplicates().shape[0]} de {df.shape[0]}\\n\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _remove_childhood_columns(df):\n",
    "    # Remove columns with `INF_` in the name - Childhood Education data\n",
    "    childhood_education_columns = [col_name for col_name in df if \"INF_\" in col_name]\n",
    "    if childhood_education_columns:\n",
    "        print(\n",
    "            f\"***Removing {len(childhood_education_columns)} columns:\",\n",
    "            \", \".join(childhood_education_columns),\n",
    "        )\n",
    "        df.drop(childhood_education_columns, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "def _extract_year(string):\n",
    "    match = re.search(r\"\\b\\d{4}(?!\\d)\", string)\n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge year data\n",
    "TARGET_DATASET = \"TXT_CLEAN\"\n",
    "\n",
    "\n",
    "def _merge_year_data(year_data_dict, external_data_df, year_dataset):\n",
    "    total_colunas = year_data_dict[TARGET_DATASET].shape[1]\n",
    "\n",
    "    # Check for NaN values in the TXT_FUN_TX_EVASAO_TOTAL and TXT_MED_TX_EVASAO_TOTAL columns\n",
    "    print(\n",
    "        \"Número de linhas com TXT_FUN_TX_EVASAO_TOTAL e TXT_MED_TX_EVASAO_TOTAL como NaN:\",\n",
    "        year_data_dict[TARGET_DATASET]\n",
    "        .query(\"@pd.isna(TXT_FUN_TX_EVASAO_TOTAL) & @pd.isna(TXT_MED_TX_EVASAO_TOTAL)\")\n",
    "        .shape[0],\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\">>>{TARGET_DATASET} add {year_data_dict[TARGET_DATASET].shape[1]} new features\"\n",
    "    )\n",
    "\n",
    "    # Merge data\n",
    "    merged_data = year_data_dict[TARGET_DATASET]  # use TXT_CLEAN_* as base\n",
    "    for key, data in year_data_dict.items():\n",
    "        if key != TARGET_DATASET:\n",
    "            merge_columns_set = list(set(MERGE_COLUMNS).intersection(data.columns))\n",
    "\n",
    "            if len(merge_columns_set) < 3:\n",
    "                print(\n",
    "                    f\"\\n!!!!Warning: {key} will be merged with only {merge_columns_set} columns\\n\"\n",
    "                )\n",
    "\n",
    "            print(f\"Merging {key}...\")\n",
    "            total_colunas += data.shape[1] - len(merge_columns_set)\n",
    "            print(f\">>>{key} add {data.shape[1] - len(merge_columns_set)} new features\")\n",
    "            merged_data = pd.merge(merged_data, data, on=merge_columns_set, how=\"left\")\n",
    "\n",
    "    # Add external data\n",
    "    print(f\"Merging external...\")\n",
    "    total_colunas += 2\n",
    "    print(f\">>>external_data add 2 new features\")\n",
    "    current_year = _extract_year(year_dataset)\n",
    "    external_data_current_year = external_data_df[\n",
    "        [\n",
    "            \"CO_MUNICIPIO\",\n",
    "            f\"PIB_{current_year}\",\n",
    "            f\"PERCENTUAL_FAMILIAS_PBF_{current_year}\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Add column with year of the dataset\n",
    "    total_colunas += 1\n",
    "    print(f\">>>ANO add 1 new feature\")\n",
    "    merged_data[\"ANO\"] = current_year\n",
    "\n",
    "    # Add covid column, 1 for 2020 & 2021 and 0 for other years\n",
    "    # TODO: ver se pode fazer isso mesmo para nosso algoritmo...\n",
    "    total_colunas += 1\n",
    "    print(f\">>>PANDEMIA_COVID add 1 new feature\")\n",
    "    merged_data[\"PANDEMIA_COVID\"] = 1 if current_year in [\"2020\", \"2021\"] else 0\n",
    "\n",
    "    merged_data = pd.merge(\n",
    "        merged_data, external_data_current_year, on=PRIMARY_KEY, how=\"left\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Finished merging data for {year_dataset}. Total de colunas: {total_colunas}\"\n",
    "    )\n",
    "    return merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build datasets for all years\n",
    "years = [f\"{year}_NCR\" for year in range(2013, 2022)]\n",
    "# years = [f\"{year}\" for year in range(2013, 2022)]\n",
    "\n",
    "# Tables with information of all years\n",
    "external_data_df = pd.read_csv(\n",
    "    os.path.join(INTERIM_DATA_DIR, \"external_data.csv\"), delimiter=\";\"\n",
    ")\n",
    "\n",
    "for year in years:\n",
    "    print(f\"\\n\\n---------- Start processing {year}... ----------\")\n",
    "\n",
    "    year_data_dict = {}\n",
    "    current_year_files = os.listdir(os.path.join(INTERIM_DATA_DIR, year))\n",
    "\n",
    "    for file in current_year_files:\n",
    "\n",
    "        file_path = os.path.join(INTERIM_DATA_DIR, year, file)\n",
    "        print(f\"Loading {file_path}\")\n",
    "\n",
    "        dataset_name = file.rstrip(\".csv\")\n",
    "        year_data_dict[dataset_name] = pd.read_csv(file_path, delimiter=\";\")\n",
    "\n",
    "        ########################################################\n",
    "        # Ajustes para o merge\n",
    "        if TARGET_DATASET in dataset_name:\n",
    "            year_data_dict[TARGET_DATASET].rename(\n",
    "                columns={\"NO_LOCALIZACAO\": \"NO_CATEGORIA\"}, inplace=True\n",
    "            )\n",
    "        ########################################################\n",
    "\n",
    "        # Remove unnecessary columns common to all datasets\n",
    "        existing_columns_to_drop = set(DROP_COLUMNS_SET).intersection(\n",
    "            year_data_dict[dataset_name].columns\n",
    "        )\n",
    "        print(\n",
    "            f\"***Removing {len(existing_columns_to_drop)} columns:\",\n",
    "            \", \".join(existing_columns_to_drop),\n",
    "        )\n",
    "        year_data_dict[dataset_name].drop(\n",
    "            existing_columns_to_drop, axis=1, inplace=True\n",
    "        )\n",
    "        # Remove columns with `INF_` in the name - Childhood Education data\n",
    "        _remove_childhood_columns(year_data_dict[dataset_name])\n",
    "        # Replace , to .\n",
    "        year_data_dict[dataset_name].replace(\n",
    "            regex=r\",(\\d+)\", value=r\".\\1\", inplace=True\n",
    "        )\n",
    "        # Remove \"--\" and \"***\" string from empty cells\n",
    "        year_data_dict[dataset_name].replace(\"--\", np.nan, inplace=True)\n",
    "        year_data_dict[dataset_name].replace(\"***\", np.nan, inplace=True)\n",
    "        # Cast columns to float\n",
    "        year_data_dict[dataset_name] = _cast_columns_to_float(\n",
    "            year_data_dict[dataset_name]\n",
    "        )\n",
    "        # Rename columns to add table prefix\n",
    "        prefix = dataset_name.split(\"_\")[0]\n",
    "        year_data_dict[dataset_name] = _add_prefix_header(\n",
    "            year_data_dict[dataset_name], prefix\n",
    "        )\n",
    "\n",
    "        # Add state code column\n",
    "        if \"TXT\" in dataset_name:\n",
    "            year_data_dict[dataset_name][\"TXT_NO_UF\"] = year_data_dict[dataset_name][\n",
    "                \"TXT_NO_UF\"\n",
    "            ].map(state_code_map)\n",
    "            year_data_dict[dataset_name].rename(\n",
    "                columns={\"TXT_NO_UF\": \"UF_CODE\"}, inplace=True\n",
    "            )\n",
    "\n",
    "    print(f\"\\n---------- Start merging {year} data... ----------\")\n",
    "    merged_data = _merge_year_data(year_data_dict, external_data_df, year)\n",
    "\n",
    "    _get_df_info(merged_data, year)\n",
    "\n",
    "    # Save data\n",
    "    print(f\"Saving data for {year}...\")\n",
    "    output_dir = os.path.join(PROCESSED_DATA_DIR, year)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    merged_data.to_csv(\n",
    "        os.path.join(output_dir, \"complete_data.csv\"), sep=\";\", index=False\n",
    "    )\n",
    "\n",
    "    # Save sliced data: NO_CATEGORIA==Total and NO_DEPENDENCIA==Total\n",
    "    total_total_data = merged_data[\n",
    "        (merged_data[\"NO_CATEGORIA\"] == \"Total\")\n",
    "        & (merged_data[\"NO_DEPENDENCIA\"] == \"Total\")\n",
    "    ].copy()\n",
    "    total_total_data.drop([\"NO_CATEGORIA\", \"NO_DEPENDENCIA\"], axis=1, inplace=True)\n",
    "\n",
    "    total_total_data.to_csv(\n",
    "        os.path.join(output_dir, \"total_total_data.csv\"), sep=\";\", index=False\n",
    "    )\n",
    "\n",
    "    # Save sliced data: Only data without FUN columns\n",
    "    total_total_data_med = total_total_data.filter(regex=\"^(?!.*FUN)\")\n",
    "    total_total_data_med.to_csv(\n",
    "        os.path.join(output_dir, \"total_total_data_med.csv\"), sep=\";\", index=False\n",
    "    )\n",
    "\n",
    "    # Save sliced data: Only data without MED columns\n",
    "    total_total_data_fun = total_total_data.filter(regex=\"^(?!.*MED)\")\n",
    "    total_total_data_fun.to_csv(\n",
    "        os.path.join(output_dir, \"total_total_data_fun.csv\"), sep=\";\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------- Start building final dataset... ----------\n",
      "Loading data from 2013_NCR...\n",
      "2013_NCR add 23873 new rows to final_complete_data\n",
      "2013_NCR add 5564 new rows to total_total_data\n",
      "2013_NCR add 5564 new rows to total_total_data_fun\n",
      "2013_NCR add 5564 new rows to total_total_data_fun\n",
      "Loading data from 2014_NCR...\n",
      "2014_NCR add 23874 new rows to final_complete_data\n",
      "2014_NCR add 5569 new rows to total_total_data\n",
      "2014_NCR add 5569 new rows to total_total_data_fun\n",
      "2014_NCR add 5569 new rows to total_total_data_fun\n",
      "Loading data from 2015_NCR...\n",
      "2015_NCR add 23850 new rows to final_complete_data\n",
      "2015_NCR add 5569 new rows to total_total_data\n",
      "2015_NCR add 5569 new rows to total_total_data_fun\n",
      "2015_NCR add 5569 new rows to total_total_data_fun\n",
      "Loading data from 2016_NCR...\n",
      "2016_NCR add 23846 new rows to final_complete_data\n",
      "2016_NCR add 5569 new rows to total_total_data\n",
      "2016_NCR add 5569 new rows to total_total_data_fun\n",
      "2016_NCR add 5569 new rows to total_total_data_fun\n",
      "Loading data from 2017_NCR...\n",
      "2017_NCR add 23843 new rows to final_complete_data\n",
      "2017_NCR add 5569 new rows to total_total_data\n",
      "2017_NCR add 5569 new rows to total_total_data_fun\n",
      "2017_NCR add 5569 new rows to total_total_data_fun\n",
      "Loading data from 2018_NCR...\n",
      "2018_NCR add 23816 new rows to final_complete_data\n",
      "2018_NCR add 5569 new rows to total_total_data\n",
      "2018_NCR add 5569 new rows to total_total_data_fun\n",
      "2018_NCR add 5569 new rows to total_total_data_fun\n",
      "Loading data from 2019_NCR...\n",
      "2019_NCR add 23792 new rows to final_complete_data\n",
      "2019_NCR add 5569 new rows to total_total_data\n",
      "2019_NCR add 5569 new rows to total_total_data_fun\n",
      "2019_NCR add 5569 new rows to total_total_data_fun\n",
      "Loading data from 2020_NCR...\n",
      "2020_NCR add 23775 new rows to final_complete_data\n",
      "2020_NCR add 5569 new rows to total_total_data\n",
      "2020_NCR add 5569 new rows to total_total_data_fun\n",
      "2020_NCR add 5569 new rows to total_total_data_fun\n",
      "Loading data from 2021_NCR...\n",
      "2021_NCR add 23757 new rows to final_complete_data\n",
      "2021_NCR add 5569 new rows to total_total_data\n",
      "2021_NCR add 5569 new rows to total_total_data_fun\n",
      "2021_NCR add 5569 new rows to total_total_data_fun\n",
      "------------------------ final complete data ------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 214435 entries, 0 to 23757\n",
      "Data columns (total 60 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   UF_CODE                                     214435 non-null  int64  \n",
      " 1   CO_MUNICIPIO                                214435 non-null  int64  \n",
      " 2   NO_CATEGORIA                                214435 non-null  object \n",
      " 3   NO_DEPENDENCIA                              214435 non-null  object \n",
      " 4   TXT_FUN_TX_PROMOCAO_TOTAL                   213682 non-null  float64\n",
      " 5   TXT_MED_TX_PROMOCAO_TOTAL                   176875 non-null  float64\n",
      " 6   TXT_FUN_TX_REPETENCIA_TOTAL                 213682 non-null  float64\n",
      " 7   TXT_MED_TX_REPETENCIA_TOTAL                 176875 non-null  float64\n",
      " 8   TXT_FUN_TX_EVASAO_TOTAL                     213682 non-null  float64\n",
      " 9   TXT_MED_TX_EVASAO_TOTAL                     176875 non-null  float64\n",
      " 10  TDI_FUN_TX_DIST_IDADE_SERIE_TOTAL           201365 non-null  float64\n",
      " 11  TDI_MED_TX_DIST_IDADE_SERIE_TOTAL           165617 non-null  float64\n",
      " 12  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO1               213256 non-null  float64\n",
      " 13  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO2               213256 non-null  float64\n",
      " 14  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO3               213256 non-null  float64\n",
      " 15  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO4               213256 non-null  float64\n",
      " 16  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO5               213256 non-null  float64\n",
      " 17  AFD_MED_ADEQ_DOC_GRUPO1                     177200 non-null  float64\n",
      " 18  AFD_MED_ADEQ_DOC_GRUPO2                     177200 non-null  float64\n",
      " 19  AFD_MED_ADEQ_DOC_GRUPO3                     177200 non-null  float64\n",
      " 20  AFD_MED_ADEQ_DOC_GRUPO4                     177200 non-null  float64\n",
      " 21  AFD_MED_ADEQ_DOC_GRUPO5                     177200 non-null  float64\n",
      " 22  HAD_FUN_MEDIA_TOTAL_HORAS_AULA              198601 non-null  float64\n",
      " 23  HAD_MED_MEDIA_TOTAL_HORAS_AULA              166110 non-null  float64\n",
      " 24  IRD_PERC_REG_DOC_BAIXA                      213117 non-null  float64\n",
      " 25  IRD_PERC_REG_DOC_MEDIA_BAIXA                213117 non-null  float64\n",
      " 26  IRD_PERC_REG_DOC_MEDIA_ALTA                 213117 non-null  float64\n",
      " 27  IRD_PERC_REG_DOC_ALTA                       213117 non-null  float64\n",
      " 28  DSU_FUN_PERC_DOC_SUPERIOR_TOTAL             202044 non-null  float64\n",
      " 29  DSU_MED_PERC_DOC_SUPERIOR_TOTAL             166109 non-null  float64\n",
      " 30  ATU_FUN_MEDIA_TOTAL_ALUNOS_SALA             202044 non-null  float64\n",
      " 31  ATU_MED_MEDIA_TOTAL_ALUNOS_SALA             166112 non-null  float64\n",
      " 32  ICG_PERC_COMPLX_ESCOLA_NIVEL_1              159272 non-null  float64\n",
      " 33  ICG_PERC_COMPLX_ESCOLA_NIVEL_2              159272 non-null  float64\n",
      " 34  ICG_PERC_COMPLX_ESCOLA_NIVEL_3              159272 non-null  float64\n",
      " 35  ICG_PERC_COMPLX_ESCOLA_NIVEL_4              159272 non-null  float64\n",
      " 36  ICG_PERC_COMPLX_ESCOLA_NIVEL_5              159272 non-null  float64\n",
      " 37  ICG_PERC_COMPLX_ESCOLA_NIVEL_6              159272 non-null  float64\n",
      " 38  TXR_FUN_TX_APROVACAO_TOTAL                  196748 non-null  float64\n",
      " 39  TXR_MED_TX_APROVACAO_TOTAL                  162870 non-null  float64\n",
      " 40  TXR_FUN_TX_REPROVACAO_TOTAL                 196748 non-null  float64\n",
      " 41  TXR_MED_TX_REPROVACAO_TOTAL                 162870 non-null  float64\n",
      " 42  TXR_FUN_TX_ABANDONO_TOTAL                   196748 non-null  float64\n",
      " 43  TXR_MED_TX_ABANDONO_TOTAL                   162870 non-null  float64\n",
      " 44  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_1  213276 non-null  float64\n",
      " 45  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_2  213276 non-null  float64\n",
      " 46  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_3  213276 non-null  float64\n",
      " 47  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_4  213276 non-null  float64\n",
      " 48  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_5  213276 non-null  float64\n",
      " 49  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_6  213276 non-null  float64\n",
      " 50  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_1  177227 non-null  float64\n",
      " 51  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_2  177227 non-null  float64\n",
      " 52  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_3  177227 non-null  float64\n",
      " 53  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_4  177227 non-null  float64\n",
      " 54  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_5  177227 non-null  float64\n",
      " 55  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_6  177227 non-null  float64\n",
      " 56  ANO                                         214435 non-null  int64  \n",
      " 57  PANDEMIA_COVID                              214435 non-null  int64  \n",
      " 58  PIB                                         214435 non-null  int64  \n",
      " 59  PERCENTUAL_FAMILIAS_PBF                     214435 non-null  float64\n",
      "dtypes: float64(53), int64(5), object(2)\n",
      "memory usage: 99.8+ MB\n",
      "\n",
      "REGISTROS NÃO REPETIDOS: 214435 de 214435\n",
      "\n",
      "------------------------ final total total data ------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50125 entries, 0 to 5569\n",
      "Data columns (total 58 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   UF_CODE                                     50125 non-null  int64  \n",
      " 1   CO_MUNICIPIO                                50125 non-null  int64  \n",
      " 2   TXT_FUN_TX_PROMOCAO_TOTAL                   50125 non-null  float64\n",
      " 3   TXT_MED_TX_PROMOCAO_TOTAL                   50037 non-null  float64\n",
      " 4   TXT_FUN_TX_REPETENCIA_TOTAL                 50125 non-null  float64\n",
      " 5   TXT_MED_TX_REPETENCIA_TOTAL                 50037 non-null  float64\n",
      " 6   TXT_FUN_TX_EVASAO_TOTAL                     50125 non-null  float64\n",
      " 7   TXT_MED_TX_EVASAO_TOTAL                     50037 non-null  float64\n",
      " 8   TDI_FUN_TX_DIST_IDADE_SERIE_TOTAL           50122 non-null  float64\n",
      " 9   TDI_MED_TX_DIST_IDADE_SERIE_TOTAL           50036 non-null  float64\n",
      " 10  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO1               50125 non-null  float64\n",
      " 11  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO2               50125 non-null  float64\n",
      " 12  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO3               50125 non-null  float64\n",
      " 13  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO4               50125 non-null  float64\n",
      " 14  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO5               50125 non-null  float64\n",
      " 15  AFD_MED_ADEQ_DOC_GRUPO1                     50042 non-null  float64\n",
      " 16  AFD_MED_ADEQ_DOC_GRUPO2                     50042 non-null  float64\n",
      " 17  AFD_MED_ADEQ_DOC_GRUPO3                     50042 non-null  float64\n",
      " 18  AFD_MED_ADEQ_DOC_GRUPO4                     50042 non-null  float64\n",
      " 19  AFD_MED_ADEQ_DOC_GRUPO5                     50042 non-null  float64\n",
      " 20  HAD_FUN_MEDIA_TOTAL_HORAS_AULA              50125 non-null  float64\n",
      " 21  HAD_MED_MEDIA_TOTAL_HORAS_AULA              50042 non-null  float64\n",
      " 22  IRD_PERC_REG_DOC_BAIXA                      50125 non-null  float64\n",
      " 23  IRD_PERC_REG_DOC_MEDIA_BAIXA                50125 non-null  float64\n",
      " 24  IRD_PERC_REG_DOC_MEDIA_ALTA                 50125 non-null  float64\n",
      " 25  IRD_PERC_REG_DOC_ALTA                       50125 non-null  float64\n",
      " 26  DSU_FUN_PERC_DOC_SUPERIOR_TOTAL             50125 non-null  float64\n",
      " 27  DSU_MED_PERC_DOC_SUPERIOR_TOTAL             50042 non-null  float64\n",
      " 28  ATU_FUN_MEDIA_TOTAL_ALUNOS_SALA             50125 non-null  float64\n",
      " 29  ATU_MED_MEDIA_TOTAL_ALUNOS_SALA             50042 non-null  float64\n",
      " 30  ICG_PERC_COMPLX_ESCOLA_NIVEL_1              50125 non-null  float64\n",
      " 31  ICG_PERC_COMPLX_ESCOLA_NIVEL_2              50125 non-null  float64\n",
      " 32  ICG_PERC_COMPLX_ESCOLA_NIVEL_3              50125 non-null  float64\n",
      " 33  ICG_PERC_COMPLX_ESCOLA_NIVEL_4              50125 non-null  float64\n",
      " 34  ICG_PERC_COMPLX_ESCOLA_NIVEL_5              50125 non-null  float64\n",
      " 35  ICG_PERC_COMPLX_ESCOLA_NIVEL_6              50125 non-null  float64\n",
      " 36  TXR_FUN_TX_APROVACAO_TOTAL                  50121 non-null  float64\n",
      " 37  TXR_MED_TX_APROVACAO_TOTAL                  50040 non-null  float64\n",
      " 38  TXR_FUN_TX_REPROVACAO_TOTAL                 50121 non-null  float64\n",
      " 39  TXR_MED_TX_REPROVACAO_TOTAL                 50040 non-null  float64\n",
      " 40  TXR_FUN_TX_ABANDONO_TOTAL                   50121 non-null  float64\n",
      " 41  TXR_MED_TX_ABANDONO_TOTAL                   50040 non-null  float64\n",
      " 42  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_1  50125 non-null  float64\n",
      " 43  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_2  50125 non-null  float64\n",
      " 44  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_3  50125 non-null  float64\n",
      " 45  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_4  50125 non-null  float64\n",
      " 46  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_5  50125 non-null  float64\n",
      " 47  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_6  50125 non-null  float64\n",
      " 48  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_1  50042 non-null  float64\n",
      " 49  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_2  50042 non-null  float64\n",
      " 50  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_3  50042 non-null  float64\n",
      " 51  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_4  50042 non-null  float64\n",
      " 52  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_5  50042 non-null  float64\n",
      " 53  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_6  50042 non-null  float64\n",
      " 54  ANO                                         50125 non-null  int64  \n",
      " 55  PANDEMIA_COVID                              50125 non-null  int64  \n",
      " 56  PIB                                         50125 non-null  int64  \n",
      " 57  PERCENTUAL_FAMILIAS_PBF                     50125 non-null  float64\n",
      "dtypes: float64(53), int64(5)\n",
      "memory usage: 22.6 MB\n",
      "\n",
      "REGISTROS NÃO REPETIDOS: 50125 de 50125\n",
      "\n",
      "------------------------ final total total data fun ------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50125 entries, 0 to 5569\n",
      "Data columns (total 33 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   UF_CODE                                     50125 non-null  int64  \n",
      " 1   CO_MUNICIPIO                                50125 non-null  int64  \n",
      " 2   TXT_FUN_TX_PROMOCAO_TOTAL                   50125 non-null  float64\n",
      " 3   TXT_FUN_TX_REPETENCIA_TOTAL                 50125 non-null  float64\n",
      " 4   TXT_FUN_TX_EVASAO_TOTAL                     50125 non-null  float64\n",
      " 5   TDI_FUN_TX_DIST_IDADE_SERIE_TOTAL           50122 non-null  float64\n",
      " 6   AFD_FUN_ADEQ_DOC_TOTAL_GRUPO1               50125 non-null  float64\n",
      " 7   AFD_FUN_ADEQ_DOC_TOTAL_GRUPO2               50125 non-null  float64\n",
      " 8   AFD_FUN_ADEQ_DOC_TOTAL_GRUPO3               50125 non-null  float64\n",
      " 9   AFD_FUN_ADEQ_DOC_TOTAL_GRUPO4               50125 non-null  float64\n",
      " 10  AFD_FUN_ADEQ_DOC_TOTAL_GRUPO5               50125 non-null  float64\n",
      " 11  IRD_PERC_REG_DOC_BAIXA                      50125 non-null  float64\n",
      " 12  IRD_PERC_REG_DOC_ALTA                       50125 non-null  float64\n",
      " 13  DSU_FUN_PERC_DOC_SUPERIOR_TOTAL             50125 non-null  float64\n",
      " 14  ICG_PERC_COMPLX_ESCOLA_NIVEL_1              50125 non-null  float64\n",
      " 15  ICG_PERC_COMPLX_ESCOLA_NIVEL_2              50125 non-null  float64\n",
      " 16  ICG_PERC_COMPLX_ESCOLA_NIVEL_3              50125 non-null  float64\n",
      " 17  ICG_PERC_COMPLX_ESCOLA_NIVEL_4              50125 non-null  float64\n",
      " 18  ICG_PERC_COMPLX_ESCOLA_NIVEL_5              50125 non-null  float64\n",
      " 19  ICG_PERC_COMPLX_ESCOLA_NIVEL_6              50125 non-null  float64\n",
      " 20  TXR_FUN_TX_APROVACAO_TOTAL                  50121 non-null  float64\n",
      " 21  TXR_FUN_TX_REPROVACAO_TOTAL                 50121 non-null  float64\n",
      " 22  TXR_FUN_TX_ABANDONO_TOTAL                   50121 non-null  float64\n",
      " 23  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_1  50125 non-null  float64\n",
      " 24  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_2  50125 non-null  float64\n",
      " 25  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_3  50125 non-null  float64\n",
      " 26  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_4  50125 non-null  float64\n",
      " 27  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_5  50125 non-null  float64\n",
      " 28  IED_FUN_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_6  50125 non-null  float64\n",
      " 29  ANO                                         50125 non-null  int64  \n",
      " 30  PANDEMIA_COVID                              50125 non-null  int64  \n",
      " 31  PIB                                         50125 non-null  int64  \n",
      " 32  PERCENTUAL_FAMILIAS_PBF                     50125 non-null  float64\n",
      "dtypes: float64(28), int64(5)\n",
      "memory usage: 13.0 MB\n",
      "\n",
      "REGISTROS NÃO REPETIDOS: 50125 de 50125\n",
      "\n",
      "------------------------ year data total total med ------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5570 entries, 0 to 5569\n",
      "Data columns (total 37 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   UF_CODE                                     5570 non-null   int64  \n",
      " 1   CO_MUNICIPIO                                5570 non-null   int64  \n",
      " 2   TXT_MED_TX_PROMOCAO_TOTAL                   5561 non-null   float64\n",
      " 3   TXT_MED_TX_REPETENCIA_TOTAL                 5561 non-null   float64\n",
      " 4   TXT_MED_TX_EVASAO_TOTAL                     5561 non-null   float64\n",
      " 5   TDI_MED_TX_DIST_IDADE_SERIE_TOTAL           5561 non-null   float64\n",
      " 6   AFD_MED_ADEQ_DOC_GRUPO1                     5561 non-null   float64\n",
      " 7   AFD_MED_ADEQ_DOC_GRUPO2                     5561 non-null   float64\n",
      " 8   AFD_MED_ADEQ_DOC_GRUPO3                     5561 non-null   float64\n",
      " 9   AFD_MED_ADEQ_DOC_GRUPO4                     5561 non-null   float64\n",
      " 10  AFD_MED_ADEQ_DOC_GRUPO5                     5561 non-null   float64\n",
      " 11  HAD_MED_MEDIA_TOTAL_HORAS_AULA              5561 non-null   float64\n",
      " 12  IRD_PERC_REG_DOC_BAIXA                      5570 non-null   float64\n",
      " 13  IRD_PERC_REG_DOC_MEDIA_BAIXA                5570 non-null   float64\n",
      " 14  IRD_PERC_REG_DOC_MEDIA_ALTA                 5570 non-null   float64\n",
      " 15  IRD_PERC_REG_DOC_ALTA                       5570 non-null   float64\n",
      " 16  DSU_MED_PERC_DOC_SUPERIOR_TOTAL             5561 non-null   float64\n",
      " 17  ATU_MED_MEDIA_TOTAL_ALUNOS_SALA             5561 non-null   float64\n",
      " 18  ICG_PERC_COMPLX_ESCOLA_NIVEL_1              5570 non-null   float64\n",
      " 19  ICG_PERC_COMPLX_ESCOLA_NIVEL_2              5570 non-null   float64\n",
      " 20  ICG_PERC_COMPLX_ESCOLA_NIVEL_3              5570 non-null   float64\n",
      " 21  ICG_PERC_COMPLX_ESCOLA_NIVEL_4              5570 non-null   float64\n",
      " 22  ICG_PERC_COMPLX_ESCOLA_NIVEL_5              5570 non-null   float64\n",
      " 23  ICG_PERC_COMPLX_ESCOLA_NIVEL_6              5570 non-null   float64\n",
      " 24  TXR_MED_TX_APROVACAO_TOTAL                  5561 non-null   float64\n",
      " 25  TXR_MED_TX_REPROVACAO_TOTAL                 5561 non-null   float64\n",
      " 26  TXR_MED_TX_ABANDONO_TOTAL                   5561 non-null   float64\n",
      " 27  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_1  5561 non-null   float64\n",
      " 28  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_2  5561 non-null   float64\n",
      " 29  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_3  5561 non-null   float64\n",
      " 30  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_4  5561 non-null   float64\n",
      " 31  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_5  5561 non-null   float64\n",
      " 32  IED_MED_PERC_DOC_POR_ESFORCO_TOTAL_NIVEL_6  5561 non-null   float64\n",
      " 33  ANO                                         5570 non-null   int64  \n",
      " 34  PANDEMIA_COVID                              5570 non-null   int64  \n",
      " 35  PIB                                         5570 non-null   int64  \n",
      " 36  PERCENTUAL_FAMILIAS_PBF                     5570 non-null   float64\n",
      "dtypes: float64(32), int64(5)\n",
      "memory usage: 1.6 MB\n",
      "\n",
      "REGISTROS NÃO REPETIDOS: 5570 de 5570\n",
      "\n",
      ">>>>> final_complete_data has 94 useless rows of 214435\n",
      ">>>>> final_complete_data has 214341 rows now!\n",
      ">>>>> final_total_total_data_med has 88 useless rows of 50125\n",
      ">>>>> final_total_total_data_med has 50037 rows now!\n",
      "Saving final data...\n",
      "Removing NaN rows from final_complete_data. Total rows before: 214341  Total rows after: 133752\n",
      "Removing NaN rows from final_total_total_data. Total rows before: 50125  Total rows after: 50022\n",
      "Removing NaN rows from final_total_total_data_fun. Total rows before: 50125  Total rows after: 50118\n",
      "Removing NaN rows from final_total_total_data_med. Total rows before: 5570  Total rows after: 5561\n"
     ]
    }
   ],
   "source": [
    "# Build final dataset with all years\n",
    "years = [f\"{year}_NCR\" for year in range(2013, 2022)]\n",
    "# years = [f\"{year}\" for year in range(2013, 2022)]\n",
    "\n",
    "\n",
    "def remove_year(col_name):\n",
    "    if \"PIB_\" in col_name or \"PERCENTUAL_FAMILIAS_PBF_\" in col_name:\n",
    "        return col_name.rsplit(\"_\", 1)[0]\n",
    "    return col_name\n",
    "\n",
    "\n",
    "print(\"\\n\\n---------- Start building final dataset... ----------\")\n",
    "final_complete_data = pd.DataFrame()\n",
    "final_total_total_data = pd.DataFrame()\n",
    "final_total_total_data_fun = pd.DataFrame()\n",
    "final_total_total_data_med = pd.DataFrame()\n",
    "\n",
    "\n",
    "for folder in years:\n",
    "    print(f\"Loading data from {folder}...\")\n",
    "\n",
    "    ############################ final_complete_data ##############################\n",
    "    year_complete_data = pd.read_csv(\n",
    "        os.path.join(PROCESSED_DATA_DIR, folder, \"complete_data.csv\"), delimiter=\";\"\n",
    "    )\n",
    "    year_complete_data.rename(columns=remove_year, inplace=True)\n",
    "    print(\n",
    "        f\"{folder} add {year_complete_data.shape[0]-1} new rows to final_complete_data\"\n",
    "    )\n",
    "    final_complete_data = pd.concat([final_complete_data, year_complete_data])\n",
    "    ############################# final_total_total_data #############################\n",
    "    year_data_total_total = pd.read_csv(\n",
    "        os.path.join(PROCESSED_DATA_DIR, folder, \"total_total_data.csv\"), delimiter=\";\"\n",
    "    )\n",
    "    year_data_total_total.rename(columns=remove_year, inplace=True)\n",
    "    print(\n",
    "        f\"{folder} add {year_data_total_total.shape[0]-1} new rows to total_total_data\"\n",
    "    )\n",
    "    final_total_total_data = pd.concat([final_total_total_data, year_data_total_total])\n",
    "    ############################ final_total_total_data_fun ##############################\n",
    "    year_data_total_total_fun = pd.read_csv(\n",
    "        os.path.join(PROCESSED_DATA_DIR, folder, \"total_total_data_fun.csv\"),\n",
    "        delimiter=\";\",\n",
    "    )\n",
    "    year_data_total_total_fun.rename(columns=remove_year, inplace=True)\n",
    "    print(\n",
    "        f\"{folder} add {year_data_total_total_fun.shape[0]-1} new rows to total_total_data_fun\"\n",
    "    )\n",
    "    final_total_total_data_fun = pd.concat(\n",
    "        [final_total_total_data_fun, year_data_total_total_fun]\n",
    "    )\n",
    "    ######################### final_total_total_data_med #################################\n",
    "    year_data_total_total_med = pd.read_csv(\n",
    "        os.path.join(PROCESSED_DATA_DIR, folder, \"total_total_data_med.csv\"),\n",
    "        delimiter=\";\",\n",
    "    )\n",
    "    year_data_total_total_med.rename(columns=remove_year, inplace=True)\n",
    "    print(\n",
    "        f\"{folder} add {year_data_total_total_med.shape[0]-1} new rows to total_total_data_fun\"\n",
    "    )\n",
    "    final_total_total_data_med = pd.concat(\n",
    "        [final_total_total_data_med, year_data_total_total_med]\n",
    "    )\n",
    "\n",
    "_get_df_info(final_complete_data, \"final complete data\")\n",
    "_get_df_info(final_total_total_data, \"final total total data\")\n",
    "_get_df_info(final_total_total_data_fun, \"final total total data fun\")\n",
    "_get_df_info(year_data_total_total_med, \"year data total total med\")\n",
    "\n",
    "# Drop useless rows\n",
    "for df, df_name in [\n",
    "    (final_complete_data, \"final_complete_data\"),\n",
    "    (final_total_total_data, \"final_total_total_data\"),\n",
    "    (final_total_total_data_fun, \"final_total_total_data_fun\"),\n",
    "    (final_total_total_data_med, \"final_total_total_data_med\"),\n",
    "]:\n",
    "    if \"fun\" in df_name:\n",
    "        useless_row = [\"TXT_FUN_TX_EVASAO_TOTAL\"]\n",
    "    elif \"med\" in df_name:\n",
    "        useless_row = [\"TXT_MED_TX_EVASAO_TOTAL\"]\n",
    "    else:\n",
    "        useless_row = [\"TXT_FUN_TX_EVASAO_TOTAL\", \"TXT_MED_TX_EVASAO_TOTAL\"]\n",
    "\n",
    "    num_useless_rows = df[useless_row].isna().all(axis=1).sum()\n",
    "\n",
    "    if num_useless_rows > 0:\n",
    "        print(f\">>>>> {df_name} has {num_useless_rows} useless rows of {df.shape[0]}\")\n",
    "        df.dropna(subset=useless_row, how=\"all\", inplace=True)\n",
    "        print(f\">>>>> {df_name} has {df.shape[0]} rows now!\")\n",
    "\n",
    "# Save final data\n",
    "print(\"Saving final data...\")\n",
    "save_dir = (\n",
    "    os.path.join(PROCESSED_DATA_DIR, \"final_NCR\")\n",
    "    if \"NCR\" in years[0]\n",
    "    else os.path.join(PROCESSED_DATA_DIR, \"final\")\n",
    ")\n",
    "final_complete_data.to_csv(\n",
    "    os.path.join(save_dir, \"final_complete_data.csv\"), sep=\";\", index=False\n",
    ")\n",
    "final_total_total_data.to_csv(\n",
    "    os.path.join(save_dir, \"final_total_total_data.csv\"), sep=\";\", index=False\n",
    ")\n",
    "final_total_total_data_fun.to_csv(\n",
    "    os.path.join(save_dir, \"final_total_total_data_fun.csv\"),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")\n",
    "year_data_total_total_med.to_csv(\n",
    "    os.path.join(save_dir, \"final_total_total_data_med.csv\"),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "# Remove NaN rows\n",
    "print(\n",
    "    \"Removing NaN rows from final_complete_data. Total rows before:\",\n",
    "    final_complete_data.shape[0],\n",
    "    \" Total rows after:\",\n",
    "    final_complete_data.dropna().shape[0],\n",
    ")\n",
    "final_complete_data.dropna().to_csv(\n",
    "    os.path.join(save_dir, \"final_complete_data_without_nan.csv\"), sep=\";\", index=False\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Removing NaN rows from final_total_total_data. Total rows before:\",\n",
    "    final_total_total_data.shape[0],\n",
    "    \" Total rows after:\",\n",
    "    final_total_total_data.dropna().shape[0],\n",
    ")\n",
    "final_total_total_data.dropna().to_csv(\n",
    "    os.path.join(save_dir, \"final_total_total_data_without_nan.csv\"),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Removing NaN rows from final_total_total_data_fun. Total rows before:\",\n",
    "    final_total_total_data_fun.shape[0],\n",
    "    \" Total rows after:\",\n",
    "    final_total_total_data_fun.dropna().shape[0],\n",
    ")\n",
    "final_total_total_data_fun.dropna().to_csv(\n",
    "    os.path.join(save_dir, \"final_total_total_data_fun_without_nan.csv\"),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Removing NaN rows from final_total_total_data_med. Total rows before:\",\n",
    "    year_data_total_total_med.shape[0],\n",
    "    \" Total rows after:\",\n",
    "    year_data_total_total_med.dropna().shape[0],\n",
    ")\n",
    "year_data_total_total_med.dropna().to_csv(\n",
    "    os.path.join(save_dir, \"final_total_total_data_med_without_nan.csv\"),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
